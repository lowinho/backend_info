## ğŸ§  Backend â€“ API de AnÃ¡lise de Pedidos com Dados Pessoais

O backend Ã© responsÃ¡vel por **processar, analisar e classificar pedidos** (texto ou arquivos) com base na presenÃ§a de **dados pessoais e sensÃ­veis**, conforme os princÃ­pios da **LGPD** e os critÃ©rios definidos pela **CGDF**.

Toda a API foi desenvolvida para fins de automatizaÃ§Ã£o que permitem a  identificaÃ§Ã£o de pedidos que podem ou nÃ£o serem classificados como **pÃºblico**.

## ğŸš€ Como Executar o Projeto

VocÃª pode rodar o backend de duas formas: utilizando via **VENV** (Ambiente virtual Python) ou **DOCKER** (que jÃ¡ configura o banco de dados e a IA automaticamente - Para visualizaÃ§Ã£o com **frontend**).

---
### OpÃ§Ã£o 1 ExecuÃ§Ã£o via Terminal (VENV)
O projeto utiliza um arquivo **requirements.txt** para gerenciar todas as dependÃªncias, garantindo que o ambiente de execuÃ§Ã£o seja idÃªntico ao de desenvolvimento.

* Criar e ativar o ambiente virtual (Recomendado)
O uso de um ambiente virtual (VENV) evita conflitos entre as bibliotecas do seu sistema e as do projeto.

### Criar o ambiente (Universal):
```bash
python -m venv venv
```
### Ativar o ambiente:
* No Linux / Mac:
```bash
source venv/bin/activate
```
* No Windows:
```bash
.\venv\Scripts\activate
```
### 2. Instalar as dependÃªncias
Com o ambiente devidamente ativo, instale os pacotes necessÃ¡rios:
```bash
pip install -r requirements.txt
```

### 3. Baixar o modelo de IA (Processamento de Nomes)
**ESTA ETAPA Ã‰ OBRIGATÃ“RIA.** O sistema utiliza Processamento de Linguagem Natural (NLP) para identificar nomes prÃ³prios. Para isso, Ã© necessÃ¡rio baixar o modelo treinado do SpaCy:

```bash
pip install https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.7.0/pt_core_news_lg-3.7.0-py3-none-any.whl
```
### 4. Rodar o Projeto
ApÃ³s a configuraÃ§Ã£o, vocÃª pode executar os scripts principais de acordo com a sua necessidade:


ğŸ“ ObservaÃ§Ã£o Importante: Por padrÃ£o, o script estÃ¡ configurado para ler o arquivo no caminho:
```bash
./files/AMOSTRA_e-SIC.xlsx.
```
Caso queira testar um arquivo diferente, vocÃª tem duas opÃ§Ãµes:

* Colocar o seu arquivo na pasta ./files/ com o nome AMOSTRA_e-SIC.xlsx.

* Abrir o arquivo report.py na pasta report/ e alterar a variÃ¡vel FILE_NAME para o caminho do seu novo arquivo.
### Para anÃ¡lise Standalone (Terminal):
```bash
# Entre na pasta report
cd report
# Execute o script
python report.py
```
### 5. Formato dos Dados de Entrada e SaÃ­da ğŸ“¥

### Formato de Entrada

O sistema aceita arquivos nos seguintes formatos:

* **.xlsx (Excel)**

* **.csv**

Requisitos do arquivo:

Deve conter ao menos uma coluna de texto livre, onde serÃ£o analisados os possÃ­veis dados pessoais.

Preferencialmente, a coluna deve conter no nome algo semelhante a:

**Texto Mascarado**

Caso nÃ£o exista uma coluna com esse nome, o sistema tentarÃ¡ identificar automaticamente a coluna de texto mais longa.

Opcionalmente, o arquivo pode conter uma coluna de identificaÃ§Ã£o do registro, como:

**ID, Id, id, Protocolo, protocolo**

ğŸ“ Exemplo de estrutura esperada:
```bash
# Exemplo de csv
Protocolo	Texto Mascarado
12345	Solicito informaÃ§Ãµes sobre JoÃ£o Silva, CPF 000.000.000-00...
```
### ğŸ“¤ Formato de SaÃ­da

A saÃ­da do processamento ocorre via terminal, por meio de um dashboard textual, contendo:

* ğŸ“Š Quantidade total de registros analisados

* âš ï¸ Quantidade de registros com dados pessoais identificados

* ğŸ“ˆ Taxa de incidÃªncia de PII

* â±ï¸ Tempo total de processamento

* ğŸ” Detalhamento por tipo de dado pessoal detectado, incluindo:

* CPF

* CNPJ

* Telefones

* E-mails

* EndereÃ§os

* Registros Gerais (RG, CNH, NIS, PIS, etc.)

* Dados sensÃ­veis (saÃºde, menor de idade, raÃ§a, gÃªnero, contexto social)

### OpÃ§Ã£o 2: Via Docker (Recomendado para IntegraÃ§Ã£o com Frontend ğŸ³)


---

Esta opÃ§Ã£o utiliza **Docker Compose** para orquestrar a API Flask e o banco de dados MongoDB, permitindo que o Frontend se comunique perfeitamente com o backend.

**PrÃ©-requisitos:** Docker e Docker Compose instalados.

1.  **Subir o ambiente:**
    Na pasta raiz do projeto, execute:
    ```bash
    docker compose up --build
    ```

2.  **ServiÃ§os Iniciados:**
    * **API Flask:** Rodando em `http://localhost:5000`
    * **MongoDB:** Rodando na porta `27017`
    * **Volumes:** Os dados do banco sÃ£o persistidos em `mongodb_data` e os arquivos enviados ficam na pasta `./uploads`.

3.  **Destaques da ConfiguraÃ§Ã£o Docker:**
    * **Multi-stage Build:** A imagem final Ã© otimizada e leve, contendo apenas o necessÃ¡rio para a execuÃ§Ã£o.
    * **Auto-Healthcheck:** O container da API possui verificaÃ§Ã£o automÃ¡tica de integridade.
    * **SeguranÃ§a:** A aplicaÃ§Ã£o roda com um usuÃ¡rio nÃ£o-root (`appuser`), seguindo boas prÃ¡ticas de seguranÃ§a.
    * **Hot Reload:** O volume montado em `.:/app` permite que alteraÃ§Ãµes no cÃ³digo sejam refletidas em tempo real (em modo debug).

E para visualizaÃ§Ã£o **(FRONTEND)** basta seguir as intruÃ§Ãµes do repositÃ³rio abaixo:

**[RepositÃ³rio do Frontend](https://github.com/lowinho/frontend_info)**

### Principais DependÃªncias Utilizadas

As bibliotecas abaixo sÃ£o utilizadas no backend, organizadas por finalidade:

ğŸŒ Framework da API

* **Flask** â€“ Framework web principal da API

* **flask-cors** â€“ Habilita comunicaÃ§Ã£o entre frontend e backend

* **python-dotenv** â€“ Gerenciamento de variÃ¡veis de ambiente

ğŸ“Š Processamento de Dados

* **pandas** â€“ Leitura e manipulaÃ§Ã£o de dados estruturados

* **openpyxl** â€“ Suporte a arquivos Excel (.xlsx)

ğŸ§  DetecÃ§Ã£o de Dados Pessoais (NLP)

* **spaCy** â€“ Processamento de linguagem natural para identificaÃ§Ã£o de PII

* **phonenumbers** â€“ ValidaÃ§Ã£o e detecÃ§Ã£o de nÃºmeros telefÃ´nicos

ğŸ—„ï¸ Banco de Dados

* **pymongo** â€“ IntegraÃ§Ã£o com MongoDB

ğŸ” SeguranÃ§a e Utilidades

* **cryptography** â€“ Suporte a prÃ¡ticas de seguranÃ§a e criptografia

* **werkzeug** â€“ UtilitÃ¡rios internos do Flask

* **python-multipart** â€“ Upload de arquivos via formulÃ¡rio