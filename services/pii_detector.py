import pandas as pd
import spacy
import re
from typing import Dict, List, Set, Tuple
from collections import defaultdict

class PIIDetector:
    """
    Detector de PII V6.0 - Valida√ß√£o por Dicion√°rio (IBGE)
    Foco: Precis√£o Extrema em Nomes. S√≥ aceita se tiver estrutura Nome + Sobrenome
    e contiver elementos comuns da onom√°stica brasileira.
    """
    
    PII_TYPES = {
        # --- Identificadores Pessoais ---
        'PERSON_NAME': 'Nome de Pessoa',
        'CPF': 'Cadastro de Pessoa F√≠sica',
        'RG': 'Registro Geral',
        'CNPJ': 'Cadastro Nacional de Pessoa Jur√≠dica',
        
        # --- Contatos ---
        'EMAIL': 'Endere√ßo de E-mail',
        'PHONE': 'N√∫mero de Telefone',
        
        # --- Tradu√ß√£o dos Gen√©ricos ---
        'FULL_ADDRESS': 'Endere√ßo Completo',
        'DOC_GENERICO': 'Documento Gen√©rico',
        
        # --- Dados Sens√≠veis ---
        'SENSITIVE_HEALTH': 'Dados de Sa√∫de (Sens√≠vel)',
        'SENSITIVE_MINOR': 'Dados de Menor de Idade (Sens√≠vel)',
        'SENSITIVE_SOCIAL': 'Dados Sociais (Sens√≠vel)'
    }

    # --- BASE DE CONHECIMENTO (TOP NOMES/SOBRENOMES BRASIL - Fonte: IBGE) ---
    COMMON_NAMES = {
        'maria', 'joao', 'ana', 'carlos', 'paulo', 'jose', 'lucas', 'pedro',
        'marcos', 'luiz', 'gabriel', 'rafael', 'francisco', 'marcelo', 'bruno',
        'felipe', 'guilherme', 'rodrigo', 'antonio', 'mateus', 'andre', 'fernando',
        'fabio', 'leonardo', 'gustavo', 'juliana', 'patricia', 'aline', 'camila',
        'bruna', 'jessica', 'leticia', 'julia', 'luciana', 'amanda', 'mariana',
        'vanessa', 'alice', 'beatriz', 'larissa', 'debora', 'claudia', 'carol',
        'carolina', 'sandra', 'regina', 'roberta', 'edson', 'sergio', 'vitor',
        'thiago', 'alexandre', 'eduardo', 'daniel', 'renato', 'ricardo', 'jorge',
        'samuel', 'diego', 'leandro', 'tiago', 'anderson', 'claudio', 'marcio',
        'mauro', 'roberto', 'wellington', 'wallace', 'robson', 'cristiano',
        'geraldo', 'raimundo', 'sebastiao', 'miguel', 'arthur', 'heitor', 'bernardo',
        'davi', 'theo', 'lorenzo', 'gabriel', 'gael', 'bento', 'helena', 'laura',
        'sophia', 'manuela', 'maite', 'liz', 'cecilia', 'elisa', 'mait√™', 'elo√°'
    }

    COMMON_SURNAMES = {
        'silva', 'santos', 'oliveira', 'souza', 'rodrigues', 'ferreira', 'alves',
        'pereira', 'lima', 'gomes', 'costa', 'ribeiro', 'martins', 'carvalho',
        'almeida', 'lopes', 'soares', 'fernandes', 'vieira', 'barbosa', 'rocha',
        'dias', 'nascimento', 'andrade', 'moreira', 'nunes', 'marques', 'machado',
        'mendes', 'freitas', 'cardoso', 'ramos', 'goncalves', 'santana', 'teixeira',
        'cavalcanti', 'moura', 'campos', 'jesus', 'pinto', 'araujo', 'leite',
        'barros', 'farias', 'cunha', 'reis', 'siqueira', 'moraes', 'castro',
        'batista', 'neves', 'rosa', 'medeiros', 'dantas', 'conceicao', 'braga',
        'filho', 'neto', 'junior', 'sobrinho', 'mota', 'vasconcelos', 'cruz',
        'viana', 'peixoto', 'maia', 'monteiro', 'coelho', 'correia', 'brito'
    }

    def __init__(self):
        print("üîç Inicializando PIIDetector V6.0 (Valida√ß√£o IBGE)...")
        try:
            self.nlp = spacy.load("pt_core_news_lg")
            # Otimiza√ß√£o
            pipes_to_disable = ['parser', 'tagger', 'morphologizer', 'lemmatizer']
            existing_pipes = [p for p in pipes_to_disable if p in self.nlp.pipe_names]
            if existing_pipes:
                self.nlp.disable_pipes(existing_pipes)
        except:
            print("‚ö†Ô∏è Erro NLP. Usando apenas Regex.")
            self.nlp = None

        self.phone_patterns = [
            r'\b(?:\(?\d{2}\)?\s?)?(?:9\s?)?[5-9]\d{3}[-.\s]\d{4}\b',
            r'(?i)(?:tel|cel|zap|whatsapp|contato|fone)[:\s\.]+\d{8,12}\b'
        ]

        self.regex_patterns = {
            'CPF': r'(?:\b\d{3}\.\d{3}\.\d{3}-\d{2}\b)|(?<=CPF[:\s])\s*\d{11}',
            'CNPJ': r'\b\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2}\b',
            'EMAIL': r'\b[A-Za-z0-9._%+-]+@(?!.*\.gov\.br)[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'FULL_ADDRESS': r'(?i)\b(?:Rua|Av\.|Avenida|Q\.|Qd\.|Quadra|SQN|SQS|SHN|SHS|CLN|CRN|SRES|SHDF|Cond\.|Bloco|Bl\.|Lote|Lt\.|Conjunto|Conj\.)\s+[A-Za-z0-9\s,.-]{1,100}(?:(?:\b\d+|[A-Z]\b))',
            'DOC_GENERICO': r'(?i)(?:OAB|CNH|Matr[√≠i]cula|NIS|PIS)[:\s\.]+\d{3,15}',
            'RG': r'(?i)(?:RG|Identidade)[:\s\.]+\d{1,10}'
        }

        self.sensitive_keywords = {
            'SENSITIVE_HEALTH': [r'\bc[√¢a]ncer\b', r'\boncologia\b', r'\bhiv\b', r'\baids\b', r'\basm[√°a]tico\b', r'\bminha doen[√ßc]a\b', r'\blaudo m[√©e]dico\b', r'\bCID\s?[A-Z]\d', r'\btranstorno\b', r'\bdepress[√£a]o\b', r'\bdefici[√™e]ncia\b', r'\bautis'],
            'SENSITIVE_MINOR': [r'\bmenor de idade\b', r'\bcrian[√ßc]a\b', r'\bfilh[ao] (?:de )?menor\b', r'\btutela\b', r'\bcreche\b', r'\balun[ao]\b'],
            'SENSITIVE_SOCIAL': [r'\bvulnerabilidade\b', r'\baux[√≠i]lio emergencial\b', r'\bcesta b[√°a]sica\b', r'\bbolsa fam[√≠i]lia\b']
        }

    def detect_and_redact(self, text: str) -> Tuple[str, Dict[str, int]]:
        if pd.isna(text) or not isinstance(text, str):
            return text, {}
        
        indices_to_mask = set()
        pii_stats = defaultdict(int)
        
        # 1. Regex Padr√£o
        for pii_type, pattern in self.regex_patterns.items():
            for match in re.finditer(pattern, text):
                indices_to_mask.update(range(match.start(), match.end()))
                pii_stats[pii_type] += 1

        # 2. Telefones (H√≠brido)
        for pattern in self.phone_patterns:
            for match in re.finditer(pattern, text):
                match_range = set(range(match.start(), match.end()))
                if not match_range.intersection(indices_to_mask):
                    indices_to_mask.update(match_range)
                    pii_stats['PHONE'] += 1

        # 3. Sens√≠veis
        for sens_type, keywords in self.sensitive_keywords.items():
            for kw in keywords:
                for match in re.finditer(kw, text, re.IGNORECASE):
                    indices_to_mask.update(range(match.start(), match.end()))
                    pii_stats[sens_type] += 1

        # 4. NLP COM VALIDA√á√ÉO DE DICION√ÅRIO
        if self.nlp:
            try:
                doc = self.nlp(text)
                for ent in doc.ents:
                    if ent.label_ == "PER":
                        name_candidate = ent.text.strip()
                        clean_name = re.sub(r'[^\w\s]', '', name_candidate.lower())
                        parts = clean_name.split()
                        
                        # --- REGRA 1: Estrutura (Pelo menos 2 nomes) ---
                        if len(parts) < 2:
                            continue
                        
                        # --- REGRA 2: Valida√ß√£o Cruzada (IBGE) ---
                        has_common_part = any(
                            p in self.COMMON_NAMES or p in self.COMMON_SURNAMES 
                            for p in parts
                        )
                        
                        # Exce√ß√£o: Se tiver "Dr." ou "Sra." antes
                        has_honorific = re.search(r'(?i)\b(?:dr|dra|sr|sra)\.?\s', text[max(0, ent.start_char-5):ent.start_char])

                        if not has_common_part and not has_honorific:
                            continue

                        match_range = set(range(ent.start_char, ent.end_char))
                        if not match_range.intersection(indices_to_mask):
                            indices_to_mask.update(match_range)
                            pii_stats['PERSON_NAME'] += 1
                                
            except Exception:
                pass

        # 5. Anonimiza√ß√£o
        redacted_chars = []
        for i, char in enumerate(text):
            if i in indices_to_mask:
                if char.isalnum():
                    redacted_chars.append('x')
                else:
                    redacted_chars.append(char)
            else:
                redacted_chars.append(char)
        
        return "".join(redacted_chars), dict(pii_stats)

    def get_pii_type_description(self, pii_type: str) -> str:
        return self.PII_TYPES.get(pii_type, pii_type)

    def generate_breakdown_list(self, stats: Dict[str, int], total_records: int) -> List[Dict]:
        """
        Gera a lista formatada para o JSON j√° com as descri√ß√µes traduzidas.
        """
        breakdown = []
        total_pii = sum(stats.values())
        
        sorted_stats = sorted(stats.items(), key=lambda x: x[1], reverse=True)

        for pii_type, count in sorted_stats:
            percentage = round((count / total_pii * 100), 2) if total_pii > 0 else 0
            
            breakdown.append({
                "count": count,
                "description": self.PII_TYPES.get(pii_type, pii_type), 
                "percentage": percentage,
                "type": pii_type
            })
            
        return breakdown